<!DOCTYPE html><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="UTF-8"><meta name="copyright" content="(C) Copyright 2019"><meta name="DC.rights.owner" content="(C) Copyright 2019"><meta name="DC.Type" content="concept"><meta name="description" content="You can extract, transform, and load a Hive table to a Kafka topic for real-time streaming of a large volume of Hive data. You need some understanding of write semantics and the metadata columns required for writing data to Kafka."><meta name="DC.subject" content="Hive, Kafka, write to Kafka, Hive data stream"><meta name="keywords" content="Hive, Kafka, write to Kafka, Hive data stream"><meta name="DC.Relation" scheme="URI" content="https://kafka.apache.org/0110/documentation.html"><meta name="DC.Format" content="XHTML"><meta name="DC.Identifier" content="hive_performing_hive_to_kafka_etl"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="description" content=""><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/5.8.2/css/all.css"><link rel="stylesheet" href="/common/css/main.css"><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/styles/default.min.css"><title>Writing data to Kafka</title></head><body class="hg"><header class="chead"><div class="breadcrumbs">
<span class="bread-home"><a href="/"><i class="fas fa-home"></i><span class="text-home">Cloudera Docs</span></a></span>
<span class="bread-product"></span>
<span class="bread-version"></span>
<span class="bread-category">Category</span></div>
<div class="search"><i class="search-close fas fa-times"></i><input type="text" placeholder="Search Documentation"><i class="fas fa-search"></i></div><div class="launch-search"><i class="fas fa-search"></i></div><div class="launch-pubnav"><i class="fas fa-bars"></i></div></header><main class="cmain"><div class="cpage"><article class="maincontent"><div class="inner-breadcrumbs">Concepts</div><div id="content" aria-labelledby="ariaid-title1">
 <h1 class="title topictitle1" id="ariaid-title1">Writing data to Kafka</h1>
 
 
 <div class="body conbody"><p class="shortdesc">You can extract, transform, and load a Hive table to a Kafka topic for real-time
  streaming of a large volume of Hive data. You need some understanding of write semantics and the
  metadata columns required for writing data to Kafka.</p>
  <section class="section"><h2 class="title sectiontitle">Write semantics</h2>
   
   <p class="p">The Hive-Kafka connector supports the following write semantics:</p>
   <ul class="ul">
    <li class="li"><code class="ph codeph">At least once </code>(default)</li>
    <li class="li"><code class="ph codeph">Exactly once</code></li>
    
   </ul>
   <dl class="dl">
    
     <dt class="dt dlterm">At least once (default)</dt>
     <dd class="dd">The default semantic. <code class="ph codeph">At least once</code> is the most common write semantic used
      by streaming engines. The internal Kafka producer retries on errors. If a message is not
      delivered, the exception is raised to the task level, which causes a restart, and more
      retries. The <code class="ph codeph">At least once</code> semantic leads to one of the following conclusions: <ul class="ul">
       <li class="li">If the job succeeds, each record is guaranteed to be delivered at least once. </li>
       <li class="li">If the job fails, some of the records might be lost and some might not be sent. <p class="p">In
         this case, you can retry the query, which eventually leads to the delivery of each record
         at least once.</p>
       </li>
      </ul></dd>
    
   </dl>
   <dl class="dl">
    
     <dt class="dt dlterm">Exactly once</dt>
     <dd class="dd">Following the <code class="ph codeph">exactly once</code> semantic, the Hive job ensures that either
      every record is delivered exactly once, or nothing is delivered. You can use only Kafka
      brokers supporting the Transaction API (0.11.0.x or later). To use this semantic, you must set
      the table property <code class="ph codeph">"kafka.write.semantic"="EXACTLY_ONCE"</code>. </dd>
    
   </dl> 
  </section>
 <section class="section"><h2 class="title sectiontitle">Metadata columns</h2>
  
  <p class="p">In addition to the user row payload, the insert statement must include values for the following
    extra columns:</p>
 <dl class="dl">
  
   <dt class="dt dlterm">__key</dt>
   <dd class="dd">Although you can set the value of this metadata column to null, using a meaningful key value
      to avoid unbalanced partitions is recommended. Any binary value is valid. </dd>
  
 </dl>
  <dl class="dl">
   
    <dt class="dt dlterm">__partition</dt>
    <dd class="dd">Use null unless you want to route the record to a particular partition. Using a nonexistent
      partition value results in an error.</dd>
   
  </dl>
  <dl class="dl">
   
    <dt class="dt dlterm">__offset</dt>
    <dd class="dd">You cannot set this value, which is fixed at <code class="ph codeph">-1</code>. </dd>
   
  </dl>
  <dl class="dl">
   
     <dt class="dt dlterm">__timestamp</dt>
     <dd class="dd">You can set this value to a meaningful timestamp, represented as the number of milliseconds
      since epoch. Optionally, you can set this value to <code class="ph codeph">null</code> or
       <code class="ph codeph">-1</code>, which means that the Kafka broker strategy sets the timestamp
      column.</dd>
    
  </dl>
 </section>
  
 </div>
<nav role="navigation" class="related-links"><div class="linklist relinfo"><strong>Related information</strong><br><div><a class="link" href="https://kafka.apache.org/0110/documentation.html" target="_blank">Apache Kafka Documentation</a></div></div></nav></div></article><div class="short-prev"><a href="">«</a></div><div class="short-next"><a href="">»</a></div><div class="up"></div><div class="prev"><a href="">« Getting Started with Apache Nifi</a></div><div class="next">Getting Started: <a href="">Terminology Used in This Guide »</a></div></div><aside class="pubmenu"><div class="product-title"><img class="product-logo" src="/common/img/smaller_icons/icon-hdf.png"><span class="product-name">Cloudera Data Platform</span></div><nav class="ctoc"></nav></aside></main><div class="logo"><a href="/"><img src="//www.cloudera.com/apps/settings/wcm/designs/www/clientlibs/css/assets/icons/favicon/apple-touch-icon-152x152.png"></a></div><nav class="product-drawer"><div class="full-logo"><img src="/common/img/cloudera.png"></div><ul class="products"><li class="cat">Data Platforms</li><li><img src="/common/img/mini_icons/icon-ambari.png"><span class="text">Ambari</span></li><li><img src="/common/img/mini_icons/icon-hdp.png"><span class="text">Data Platform</span></li><li class="active"><img src="/common/img/mini_icons/icon-hdf.png"><span class="text">Dataflow</span></li><li><img src="/common/img/mini_icons/icon-smartsense.png"><span class="text">Smartsense</span></li><li><img src="/common/img/mini_icons/icon-cybersecurity.png"><span class="text">Cybersecurity</span></li><li class="cat">Data Services</li><li><img src="/common/img/mini_icons/icon-dataplane.png"><span class="text">DataPlane Core</span></li><li><img src="/common/img/mini_icons/icon-studio.png"><span class="text">Data Analytics Studio</span></li><li><img src="/common/img/mini_icons/icon-datasteward.png"><span class="text">Data Steward Studio</span></li><li class="cat">Cloud Services</li><li><img src="/common/img/mini_icons/icon-cloudbreak.png"><span class="text">Cloudbreak</span></li><li><img src="/common/img/mini_icons/icon-hdcloud.png"><span class="text">HDCloud for AWS</span></li></ul><div class="open-close">»</div></nav><footer></footer><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script><script src="/common/js/main.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/highlight.min.js" class="test"></script></body></html>