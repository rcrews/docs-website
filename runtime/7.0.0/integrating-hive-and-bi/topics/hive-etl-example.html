<!DOCTYPE html><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="UTF-8"><meta name="DC.Type" content="reference"><meta name="description" content="You can create the DataFrame from any data source and include an option to write the DataFrame to a Hive table. When you write the DataFrame, the Hive Warehouse Connector creates the Hive table if it does not exist."><meta name="DC.Relation" scheme="URI" content="../topics/hive_hivewarehousesession_api_operations.html"><meta name="DC.Relation" scheme="URI" content="https://github.com/hortonworks/hive-warehouse-connector-release"><meta name="DC.Relation" scheme="URI" content="http://docs-stage.cloudera.com/HDPDocuments/CR/CR-1.0.0/developing-spark-applications/content/using_spark_hive_warehouse_connector.html"><meta name="prodname" content="Cloudera Runtime"><meta name="version" content="1"><meta name="release" content="0"><meta name="modification" content="0"><meta name="brand" content="Cloudera Runtime"><meta name="rights" content="© 2019 Cloudera, Inc."><meta name="DC.Date.Created" content="2019-04-15"><meta name="DC.Date.Modified" content="2019-04-15"><meta name="DC.Format" content="XHTML"><meta name="DC.Identifier" content="hive-etl-example"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="description" content=""><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/5.8.2/css/all.css"><link rel="stylesheet" href="/common/css/main.css"><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/styles/default.min.css"><title>Hive Warehouse Connector API Examples</title></head><body class="hg"><header class="chead"><div class="breadcrumbs">
<span class="bread-home"><a href="/"><i class="fas fa-home"></i><span class="text-home">Cloudera Docs</span></a></span>
<span class="bread-product"></span>
<span class="bread-version"></span>
<span class="bread-category">Category</span></div>
<div class="search"><i class="search-close fas fa-times"></i><input type="text" placeholder="Search Documentation"><i class="fas fa-search"></i></div><div class="launch-search"><i class="fas fa-search"></i></div><div class="launch-pubnav"><i class="fas fa-bars"></i></div></header><main class="cmain"><div class="cpage"><article class="maincontent"><div class="inner-breadcrumbs">Concepts</div><div id="content" aria-labelledby="ariaid-title1">
  <h1 class="title topictitle1" id="ariaid-title1">Hive Warehouse Connector API Examples</h1>
  
  <div class="body refbody"><p class="shortdesc">You can create the DataFrame from any data source and include an option to write the
    DataFrame to a Hive table. When you write the DataFrame, the Hive Warehouse Connector creates
    the Hive table if it does not exist. </p>
    <section class="section"><h2 class="title sectiontitle">Write a DataFrame from Spark to Hive example</h2>
      
      <div class="p">You specify one of the following <a class="xref" href="https://spark.apache.org/docs/2.3.1/api/java/org/apache/spark/sql/SaveMode.html" target="_blank">Spark <code class="ph codeph">SaveMode</code></a> modes to write a
        DataFrame to Hive:<ul class="ul" id="hive-etl-example__ul_r3m_yn4_33b">
          <li class="li">Append</li>
          <li class="li">ErrorIfExists</li>
          <li class="li">Ignore</li>
          <li class="li">Overwrite</li>
        </ul></div><p class="p">In Overwrite mode, HWC does not explicitly drop and recreate the table. HWC queries Hive to
          overwrite an existing table using LOAD DATA...OVERWRITE or INSERT OVERWRITE...</p>
      <p class="p">The following example uses Append mode.</p>
      <pre class="pre codeblock"><code>df = //Create DataFrame from any source
        
val hive = com.hortonworks.spark.sql.hive.llap.HiveWarehouseBuilder.session(spark).build()
        
df.write.format(HIVE_WAREHOUSE_CONNECTOR)
.mode("append")
.option("table", "my_Table")
.save()     </code></pre>
    </section>
    <section class="section"><h2 class="title sectiontitle">ETL example (Scala)</h2>
      
      <p class="p">Read table data from Hive, transform it in Spark, and write to a new Hive table.</p>
      <pre class="pre codeblock"><code>import com.hortonworks.hwc.HiveWarehouseSession
import com.hortonworks.hwc.HiveWarehouseSession._
val hive = HiveWarehouseSession.session(spark).build()
hive.setDatabase("tpcds_bin_partitioned_orc_1000")
val df = hive.executeQuery("select * from web_sales")
df.createOrReplaceTempView("web_sales")
hive.setDatabase("testDatabase")
hive.createTable("newTable")
.ifNotExists()
.column("ws_sold_time_sk", "bigint")
.column("ws_ship_date_sk", "bigint")
.create()
sql("SELECT ws_sold_time_sk, ws_ship_date_sk FROM web_sales WHERE ws_sold_time_sk &gt; 80000)
.write.format(HIVE_WAREHOUSE_CONNECTOR)
.mode("append")
.option("table", "newTable")
.save()</code></pre>
    </section>
    
  </div>
<nav role="navigation" class="related-links"><div class="familylinks"><div class="parentlink"><strong>Parent topic:</strong> <a class="link" href="../topics/hive_hivewarehousesession_api_operations.html" title="As a Spark developer, you execute queries to Hive using the JDBC-style HiveWarehouseSession API that supports Scala, Java, and Python. In Spark source code, you create an instance of HiveWarehouseSession. Results are returned as a DataFrame to Spark.">HiveWarehouseSession API operations</a></div></div><div class="linklist relinfo"><strong>Related information</strong><br><div><a class="link" href="https://github.com/hortonworks/hive-warehouse-connector-release" target="_blank">HiveWarehouseConnector Github project (select a feature branch)</a></div><div><a class="link" href="http://docs-stage.cloudera.com/HDPDocuments/CR/CR-1.0.0/developing-spark-applications/content/using_spark_hive_warehouse_connector.html" target="_blank">HiveWarehouseConnector for handling Apache Spark data</a></div></div></nav></div></article><div class="short-prev"><a href="">«</a></div><div class="short-next"><a href="">»</a></div><div class="up"></div><div class="prev"><a href="">« Getting Started with Apache Nifi</a></div><div class="next">Getting Started: <a href="">Terminology Used in This Guide »</a></div></div><aside class="pubmenu"><div class="product-title"><img class="product-logo" src="/common/img/smaller_icons/icon-hdf.png"><span class="product-name">Cloudera Data Platform</span></div><nav class="ctoc"></nav></aside></main><div class="logo"><a href="/"><img src="//www.cloudera.com/apps/settings/wcm/designs/www/clientlibs/css/assets/icons/favicon/apple-touch-icon-152x152.png"></a></div><nav class="product-drawer"><div class="full-logo"><img src="/common/img/cloudera.png"></div><ul class="products"><li class="cat">Data Platforms</li><li><img src="/common/img/mini_icons/icon-ambari.png"><span class="text">Ambari</span></li><li><img src="/common/img/mini_icons/icon-hdp.png"><span class="text">Data Platform</span></li><li class="active"><img src="/common/img/mini_icons/icon-hdf.png"><span class="text">Dataflow</span></li><li><img src="/common/img/mini_icons/icon-smartsense.png"><span class="text">Smartsense</span></li><li><img src="/common/img/mini_icons/icon-cybersecurity.png"><span class="text">Cybersecurity</span></li><li class="cat">Data Services</li><li><img src="/common/img/mini_icons/icon-dataplane.png"><span class="text">DataPlane Core</span></li><li><img src="/common/img/mini_icons/icon-studio.png"><span class="text">Data Analytics Studio</span></li><li><img src="/common/img/mini_icons/icon-datasteward.png"><span class="text">Data Steward Studio</span></li><li class="cat">Cloud Services</li><li><img src="/common/img/mini_icons/icon-cloudbreak.png"><span class="text">Cloudbreak</span></li><li><img src="/common/img/mini_icons/icon-hdcloud.png"><span class="text">HDCloud for AWS</span></li></ul><div class="open-close">»</div></nav><footer></footer><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script><script src="/common/js/main.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/highlight.min.js" class="test"></script></body></html>