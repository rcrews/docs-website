<!DOCTYPE html><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="UTF-8"><meta name="DC.Type" content="concept"><meta name="description" content="The Hive Warehouse Connector (HWC) is a Spark library/plugin that is launched with the Spark app. You need to understand how to use HWC to access Spark tables from Hive. You also export tables to Hive from Spark and vice versa using this connector."><meta name="DC.subject" content="Hive, Spark, Hive Warehouse Connector, HiveWarehouseConnector"><meta name="keywords" content="Hive, Spark, Hive Warehouse Connector, HiveWarehouseConnector"><meta name="DC.Relation" scheme="URI" content="../topics/hive_connecting_hive_to_bi_tools.html"><meta name="DC.Relation" scheme="URI" content="../topics/hive_apache_spark_hive_connection_configuration.html"><meta name="DC.Relation" scheme="URI" content="../topics/hive_submit_a_hivewarehouseconnector_app.html"><meta name="DC.Relation" scheme="URI" content="../topics/hive_submit_a_hivewarehouseconnector_python.html"><meta name="DC.Relation" scheme="URI" content="../topics/hive_hivewarehouseconnector_supported_types.html"><meta name="DC.Relation" scheme="URI" content="../topics/hive_hivewarehousesession_api_operations.html"><meta name="DC.Relation" scheme="URI" content="https://github.com/hortonworks/hive-warehouse-connector-release"><meta name="DC.Relation" scheme="URI" content="http://docs-stage.cloudera.com/HDPDocuments/CR/CR-1.0.0/developing-spark-applications/content/using_spark_hive_warehouse_connector.html"><meta name="DC.Relation" scheme="URI" content="https://community.hortonworks.com/content/kbentry/223626/integrating-apache-hive-with-apache-spark-hive-war.html"><meta name="DC.Relation" scheme="URI" content="https://hortonworks.com/blog/hive-warehouse-connector-use-cases/"><meta name="prodname" content="Cloudera Runtime"><meta name="version" content="1"><meta name="release" content="0"><meta name="modification" content="0"><meta name="brand" content="Cloudera Runtime"><meta name="rights" content="© 2019 Cloudera, Inc."><meta name="DC.Date.Created" content="2019-04-15"><meta name="DC.Date.Modified" content="2019-04-15"><meta name="DC.Format" content="XHTML"><meta name="DC.Identifier" content="hive_hivewarehouseconnector_for_accessing_spark"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="description" content=""><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/5.8.2/css/all.css"><link rel="stylesheet" href="/common/css/main.css"><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/styles/default.min.css"><title>Hive Warehouse Connector for accessing Apache Spark data</title></head><body class="hg"><header class="chead"><div class="breadcrumbs">
<span class="bread-home"><a href="/"><i class="fas fa-home"></i><span class="text-home">Cloudera Docs</span></a></span>
<span class="bread-product"></span>
<span class="bread-version"></span>
<span class="bread-category">Category</span></div>
<div class="search"><i class="search-close fas fa-times"></i><input type="text" placeholder="Search Documentation"><i class="fas fa-search"></i></div><div class="launch-search"><i class="fas fa-search"></i></div><div class="launch-pubnav"><i class="fas fa-bars"></i></div></header><main class="cmain"><div class="cpage"><article class="maincontent"><div class="inner-breadcrumbs">Concepts</div><div id="content" aria-labelledby="ariaid-title1">
 <h1 class="title topictitle1" id="ariaid-title1">Hive Warehouse Connector for accessing Apache Spark data</h1>
  
  
 <div class="body conbody"><p class="shortdesc">The Hive Warehouse Connector (HWC) is a Spark library/plugin that is launched with the
    Spark app. You need to understand how to use HWC to access Spark tables from Hive. You also
    export tables to Hive from Spark and vice versa using this connector.</p><p class="p">You can use the HWC API to access any type of table in Hive from Spark. When you use SparkSQL,
      standard Spark APIs access Spark tables. </p>
    <p class="p">Using the HWC, you can export tables and extracts from the Spark to Hive and from Hive to
      Spark. You export tables and extracts from Spark to Hive. You read these tables using Spark
      APIs. You write tables to Hive using the HWC. Conversely, you export tables and extracts from
      Hive to Spark by reading them using the Hive Warehouse Connector and writing them to Spark
      using Spark APIs.</p>
   <p class="p">Using the HWC, you can read and write Apache Spark DataFrames and Streaming DataFrames to and
      from Apache Hive. Apache Ranger and the HiveWarehouseConnector library provide row and column,
      fine-grained access to Spark data in Hive. </p>
   <div class="p"><strong class="ph b">Limitations</strong><ul class="ul" id="hive_hivewarehouseconnector_for_accessing_spark__ul_hdz_jdx_g3b">
     <li class="li">Currently, HWC supports tables in ORC format only.</li>
     <li class="li">The spark thrift server is not supported.</li>
   </ul></div>
   <p class="p"><strong class="ph b">Supported applications and operations</strong></p>
   <div class="p">The Hive Warehouse Connector supports the following applications:<ul class="ul" id="hive_hivewarehouseconnector_for_accessing_spark__ul_ml4_24m_d2b">
     <li class="li">Spark shell</li>
     <li class="li">PySpark</li>
     <li class="li">The spark-submit script</li>
   </ul></div>
   <div class="p">The following list describes a few of the operations supported by the Hive Warehouse Connector: <ul class="ul">
     <li class="li">Describing a table</li>
     <li class="li">Creating a table for ORC-formatted data</li>
     <li class="li">Selecting Hive data and retrieving a DataFrame</li>
     <li class="li">Writing a DataFrame to Hive in batch</li>
     <li class="li">Executing a Hive update statement</li>
     <li class="li">Reading table data from Hive, transforming it in Spark, and writing it to a new Hive
       table</li>
     <li class="li">Writing a DataFrame or Spark stream to Hive using HiveStreaming</li>
        <li class="li">Partitioning data when writing a DataFrame</li>
   </ul></div>
 </div>
<nav role="navigation" class="related-links"><ul class="ullinks"><li class="link ulchildlink"><strong><a href="../topics/hive_apache_spark_hive_connection_configuration.html">Apache Spark-Apache Hive connection configuration</a></strong><br>In Spark, you can use the Hive Warehouse Connector for accessing ACID table data in     Hive. </li><li class="link ulchildlink"><strong><a href="../topics/hive_submit_a_hivewarehouseconnector_app.html">Submit a Hive Warehouse Connector Scala or Java application</a></strong><br>You can submit an app based on the HiveWarehouseConnector library to run on Spark         Shell, PySpark, and <code class="ph codeph">spark-submit</code>.</li><li class="link ulchildlink"><strong><a href="../topics/hive_submit_a_hivewarehouseconnector_python.html">Submit a Hive Warehouse Connector Python app</a></strong><br>You can submit a Python app based on the HiveWarehouseConnector library by         following the steps to submit a Scala or Java application, and then adding a Python         package.</li><li class="link ulchildlink"><strong><a href="../topics/hive_hivewarehouseconnector_supported_types.html">Hive Warehouse Connector supported types</a></strong><br> The Hive Warehouse Connector maps most Apache Hive types to Apache Spark types and     vice versa, but there are a few exceptions that you must manage.</li><li class="link ulchildlink"><strong><a href="../topics/hive_hivewarehousesession_api_operations.html">HiveWarehouseSession API operations</a></strong><br>As a Spark developer, you execute queries to Hive using the JDBC-style     HiveWarehouseSession API that supports Scala, Java, and Python. In Spark source code, you create     an instance of HiveWarehouseSession. Results are returned as a DataFrame to Spark.  </li></ul><div class="familylinks"></div><div class="linklist relinfo"><strong>Related information</strong><br><div><a class="link" href="https://github.com/hortonworks/hive-warehouse-connector-release" target="_blank">HiveWarehouseConnector Github project (select a feature branch)</a></div><div><a class="link" href="http://docs-stage.cloudera.com/HDPDocuments/CR/CR-1.0.0/developing-spark-applications/content/using_spark_hive_warehouse_connector.html" target="_blank">HiveWarehouseConnector for handling Apache Spark data</a></div><div><a class="link" href="https://community.hortonworks.com/content/kbentry/223626/integrating-apache-hive-with-apache-spark-hive-war.html" target="_blank">Integrating Apache Hive with Apache Spark-\-Hive Warehouse Connector</a></div><div><a class="link" href="https://hortonworks.com/blog/hive-warehouse-connector-use-cases/" target="_blank">Hive Warehouse Connector Use Cases</a></div></div></nav></div></article><div class="short-prev"><a href="">«</a></div><div class="short-next"><a href="">»</a></div><div class="up"></div><div class="prev"><a href="">« Getting Started with Apache Nifi</a></div><div class="next">Getting Started: <a href="">Terminology Used in This Guide »</a></div></div><aside class="pubmenu"><div class="product-title"><img class="product-logo" src="/common/img/smaller_icons/icon-hdf.png"><span class="product-name">Cloudera Data Platform</span></div><nav class="ctoc"></nav></aside></main><div class="logo"><a href="/"><img src="//www.cloudera.com/apps/settings/wcm/designs/www/clientlibs/css/assets/icons/favicon/apple-touch-icon-152x152.png"></a></div><nav class="product-drawer"><div class="full-logo"><img src="/common/img/cloudera.png"></div><ul class="products"><li class="cat">Data Platforms</li><li><img src="/common/img/mini_icons/icon-ambari.png"><span class="text">Ambari</span></li><li><img src="/common/img/mini_icons/icon-hdp.png"><span class="text">Data Platform</span></li><li class="active"><img src="/common/img/mini_icons/icon-hdf.png"><span class="text">Dataflow</span></li><li><img src="/common/img/mini_icons/icon-smartsense.png"><span class="text">Smartsense</span></li><li><img src="/common/img/mini_icons/icon-cybersecurity.png"><span class="text">Cybersecurity</span></li><li class="cat">Data Services</li><li><img src="/common/img/mini_icons/icon-dataplane.png"><span class="text">DataPlane Core</span></li><li><img src="/common/img/mini_icons/icon-studio.png"><span class="text">Data Analytics Studio</span></li><li><img src="/common/img/mini_icons/icon-datasteward.png"><span class="text">Data Steward Studio</span></li><li class="cat">Cloud Services</li><li><img src="/common/img/mini_icons/icon-cloudbreak.png"><span class="text">Cloudbreak</span></li><li><img src="/common/img/mini_icons/icon-hdcloud.png"><span class="text">HDCloud for AWS</span></li></ul><div class="open-close">»</div></nav><footer></footer><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script><script src="/common/js/main.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/highlight.min.js" class="test"></script></body></html>