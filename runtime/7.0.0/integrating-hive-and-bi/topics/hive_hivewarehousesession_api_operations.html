<!DOCTYPE html><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="UTF-8"><meta name="DC.Type" content="reference"><meta name="description" content="As a Spark developer, you execute queries to Hive using the JDBC-style HiveWarehouseSession API that supports Scala, Java, and Python. In Spark source code, you create an instance of HiveWarehouseSession. Results are returned as a DataFrame to Spark."><meta name="DC.subject" content="Hive, Spark, Hive Warehouse Connector, HiveWarehouseConnector"><meta name="keywords" content="Hive, Spark, Hive Warehouse Connector, HiveWarehouseConnector"><meta name="DC.Relation" scheme="URI" content="../topics/hive_hivewarehouseconnector_for_handling_apache_spark_data.html"><meta name="DC.Relation" scheme="URI" content="../topics/hive-hwc-catalog-operations.html"><meta name="DC.Relation" scheme="URI" content="../topics/hive-read-write-operations.html"><meta name="DC.Relation" scheme="URI" content="../topics/hive_use_hwc_for_streaming.html"><meta name="DC.Relation" scheme="URI" content="../topics/hive-etl-example.html"><meta name="DC.Relation" scheme="URI" content="../topics/hive-hwc-interfaces.html"><meta name="DC.Relation" scheme="URI" content="https://github.com/hortonworks/hive-warehouse-connector-release"><meta name="DC.Relation" scheme="URI" content="http://docs-stage.cloudera.com/HDPDocuments/CR/CR-1.0.0/developing-spark-applications/content/using_spark_hive_warehouse_connector.html"><meta name="DC.Relation" scheme="URI" content="https://community.hortonworks.com/content/kbentry/223626/integrating-apache-hive-with-apache-spark-hive-war.html"><meta name="DC.Relation" scheme="URI" content="https://hortonworks.com/blog/hive-warehouse-connector-use-cases/"><meta name="prodname" content="Cloudera Runtime"><meta name="version" content="1"><meta name="release" content="0"><meta name="modification" content="0"><meta name="brand" content="Cloudera Runtime"><meta name="rights" content="© 2019 Cloudera, Inc."><meta name="DC.Date.Created" content="2019-04-15"><meta name="DC.Date.Modified" content="2019-04-15"><meta name="DC.Format" content="XHTML"><meta name="DC.Identifier" content="hive_hivewarehousesession_api_operations"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="description" content=""><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/5.8.2/css/all.css"><link rel="stylesheet" href="/common/css/main.css"><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/styles/default.min.css"><title>HiveWarehouseSession API operations</title></head><body class="hg"><header class="chead"><div class="breadcrumbs">
<span class="bread-home"><a href="/"><i class="fas fa-home"></i><span class="text-home">Cloudera Docs</span></a></span>
<span class="bread-product"></span>
<span class="bread-version"></span>
<span class="bread-category">Category</span></div>
<div class="search"><i class="search-close fas fa-times"></i><input type="text" placeholder="Search Documentation"><i class="fas fa-search"></i></div><div class="launch-search"><i class="fas fa-search"></i></div><div class="launch-pubnav"><i class="fas fa-bars"></i></div></header><main class="cmain"><div class="cpage"><article class="maincontent"><div class="inner-breadcrumbs">Concepts</div><div id="content" aria-labelledby="ariaid-title1">
  <h1 class="title topictitle1" id="ariaid-title1">HiveWarehouseSession API operations</h1>
  
  
  <div class="body refbody"><p class="shortdesc">As a Spark developer, you execute queries to Hive using the JDBC-style
    HiveWarehouseSession API that supports Scala, Java, and Python. In Spark source code, you create
    an instance of HiveWarehouseSession. Results are returned as a DataFrame to Spark.  </p>
    <section class="section"><h2 class="title sectiontitle">Import statements and variables</h2>
      
      <p class="p">The following string constants are defined by the API:</p>
      <ul class="ul">
        <li class="li"><code class="ph codeph">HIVE_WAREHOUSE_CONNECTOR</code></li>
        <li class="li"><code class="ph codeph">DATAFRAME_TO_STREAM</code></li>
        <li class="li"><code class="ph codeph">STREAM_TO_STREAM</code></li>
        </ul>
      <p class="p">For more information, see the Github project for the Hive Warehouse Connector (link
        below).</p>
      <p class="p">Assuming <code class="ph codeph">spark</code> is running in an existing <code class="ph codeph">SparkSession</code>,
        use this code for imports:</p>
      <ul class="ul">
        <li class="li">Scala<div class="p">
            <pre class="pre codeblock"><code>import com.hortonworks.hwc.HiveWarehouseSession
import com.hortonworks.hwc.HiveWarehouseSession._
val hive = HiveWarehouseSession.session(spark).build()</code></pre>
          </div></li>
      </ul>
      <ul class="ul">
        <li class="li">Java<div class="p">
            <pre class="pre codeblock"><code>import com.hortonworks.hwc.HiveWarehouseSession;
import static com.hortonworks.hwc.HiveWarehouseSession.*;
HiveWarehouseSession hive = HiveWarehouseSession.session(spark).build();</code></pre>
          </div></li>
      </ul>
      <ul class="ul">
        <li class="li">Python<div class="p">
            <pre class="pre codeblock"><code>from pyspark_llap import HiveWarehouseSession
hive = HiveWarehouseSession.session(spark).build()</code></pre>
          </div></li>
      </ul>
    </section>
    
    
  </div>
<nav role="navigation" class="related-links"><ul class="ullinks"><li class="link ulchildlink"><strong><a href="../topics/hive-hwc-catalog-operations.html">Catalog operations</a></strong><br>Catalog operations include creating, dropping, and describing a Hive database and     table from Spark.</li><li class="link ulchildlink"><strong><a href="../topics/hive-read-write-operations.html">Read and write operations</a></strong><br>The API supports reading Spark tables from Hive. HWC supports push-downs of DataFrame filters and projections applied to executeQuery. You can update statements and     write DataFrames to partitioned Hive tables, perform batch writes, and use     HiveStreaming.</li><li class="link ulchildlink"><strong><a href="../topics/hive_use_hwc_for_streaming.html">Use the Hive Warehouse Connector for streaming</a></strong><br>When using HiveStreaming to write a DataFrame to Hive or a Spark Stream to Hive, you         need to escape any commas in the stream because the Hive Warehouse Connector uses the commas         as the field delimiter.</li><li class="link ulchildlink"><strong><a href="../topics/hive-etl-example.html">Hive Warehouse Connector API Examples</a></strong><br>You can create the DataFrame from any data source and include an option to write the     DataFrame to a Hive table. When you write the DataFrame, the Hive Warehouse Connector creates     the Hive table if it does not exist. </li><li class="link ulchildlink"><strong><a href="../topics/hive-hwc-interfaces.html">Hive Warehouse Connector Interfaces</a></strong><br>The HiveWarehouseSession, CreateTableBuilder, and MergeBuilder interfaces present     available HWC operations.</li></ul><div class="familylinks"><div class="parentlink"><strong>Parent topic:</strong> <a class="link" href="../topics/hive_hivewarehouseconnector_for_handling_apache_spark_data.html" title="The Hive Warehouse Connector (HWC) is a Spark library/plugin that is launched with the Spark app. You need to understand how to use HWC to access Spark tables from Hive. You also export tables to Hive from Spark and vice versa using this connector.">Hive Warehouse Connector for accessing Apache Spark data</a></div></div><div class="linklist relinfo"><strong>Related information</strong><br><div><a class="link" href="https://github.com/hortonworks/hive-warehouse-connector-release" target="_blank">HiveWarehouseConnector Github project (select a feature branch)</a></div><div><a class="link" href="http://docs-stage.cloudera.com/HDPDocuments/CR/CR-1.0.0/developing-spark-applications/content/using_spark_hive_warehouse_connector.html" target="_blank">HiveWarehouseConnector for handling Apache Spark data</a></div><div><a class="link" href="https://community.hortonworks.com/content/kbentry/223626/integrating-apache-hive-with-apache-spark-hive-war.html" target="_blank">Integrating Apache Hive with Apache Spark-\-Hive Warehouse Connector</a></div><div><a class="link" href="https://hortonworks.com/blog/hive-warehouse-connector-use-cases/" target="_blank">Hive Warehouse Connector Use Cases</a></div></div></nav></div></article><div class="short-prev"><a href="">«</a></div><div class="short-next"><a href="">»</a></div><div class="up"></div><div class="prev"><a href="">« Getting Started with Apache Nifi</a></div><div class="next">Getting Started: <a href="">Terminology Used in This Guide »</a></div></div><aside class="pubmenu"><div class="product-title"><img class="product-logo" src="/common/img/smaller_icons/icon-hdf.png"><span class="product-name">Cloudera Data Platform</span></div><nav class="ctoc"></nav></aside></main><div class="logo"><a href="/"><img src="//www.cloudera.com/apps/settings/wcm/designs/www/clientlibs/css/assets/icons/favicon/apple-touch-icon-152x152.png"></a></div><nav class="product-drawer"><div class="full-logo"><img src="/common/img/cloudera.png"></div><ul class="products"><li class="cat">Data Platforms</li><li><img src="/common/img/mini_icons/icon-ambari.png"><span class="text">Ambari</span></li><li><img src="/common/img/mini_icons/icon-hdp.png"><span class="text">Data Platform</span></li><li class="active"><img src="/common/img/mini_icons/icon-hdf.png"><span class="text">Dataflow</span></li><li><img src="/common/img/mini_icons/icon-smartsense.png"><span class="text">Smartsense</span></li><li><img src="/common/img/mini_icons/icon-cybersecurity.png"><span class="text">Cybersecurity</span></li><li class="cat">Data Services</li><li><img src="/common/img/mini_icons/icon-dataplane.png"><span class="text">DataPlane Core</span></li><li><img src="/common/img/mini_icons/icon-studio.png"><span class="text">Data Analytics Studio</span></li><li><img src="/common/img/mini_icons/icon-datasteward.png"><span class="text">Data Steward Studio</span></li><li class="cat">Cloud Services</li><li><img src="/common/img/mini_icons/icon-cloudbreak.png"><span class="text">Cloudbreak</span></li><li><img src="/common/img/mini_icons/icon-hdcloud.png"><span class="text">HDCloud for AWS</span></li></ul><div class="open-close">»</div></nav><footer></footer><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script><script src="/common/js/main.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/highlight.min.js" class="test"></script></body></html>