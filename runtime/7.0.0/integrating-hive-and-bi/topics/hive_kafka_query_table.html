<!DOCTYPE html><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="UTF-8"><meta name="copyright" content="(C) Copyright 2019"><meta name="DC.rights.owner" content="(C) Copyright 2019"><meta name="DC.Type" content="task"><meta name="description" content="You can get useful information from a table of Kafka data by running typical queries, such as counting the number of records streamed within an interval of time or defining a view of streamed data over a period of time."><meta name="DC.subject" content="Hive, Kafka, time series, Hive data stream"><meta name="keywords" content="Hive, Kafka, time series, Hive data stream"><meta name="DC.Relation" scheme="URI" content="https://kafka.apache.org/0110/documentation.html"><meta name="DC.Format" content="XHTML"><meta name="DC.Identifier" content="hive_kafka_query_table"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="description" content=""><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/5.8.2/css/all.css"><link rel="stylesheet" href="/common/css/main.css"><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/styles/default.min.css"><title>Query live data from Kafka</title></head><body class="hg"><header class="chead"><div class="breadcrumbs">
<span class="bread-home"><a href="/"><i class="fas fa-home"></i><span class="text-home">Cloudera Docs</span></a></span>
<span class="bread-product"></span>
<span class="bread-version"></span>
<span class="bread-category">Category</span></div>
<div class="search"><i class="search-close fas fa-times"></i><input type="text" placeholder="Search Documentation"><i class="fas fa-search"></i></div><div class="launch-search"><i class="fas fa-search"></i></div><div class="launch-pubnav"><i class="fas fa-bars"></i></div></header><main class="cmain"><div class="cpage"><article class="maincontent"><div class="inner-breadcrumbs">Concepts</div><div id="content" aria-labelledby="ariaid-title1">
    <h1 class="title topictitle1" id="ariaid-title1">Query live data from Kafka</h1>
    
    
    <div class="body taskbody"><p class="shortdesc">You can get useful information from a table of Kafka data by running typical queries,
        such as counting the number of records streamed within an interval of time or defining a
        view of streamed data over a period of time.</p>
        <div class="section prereq p">This task requires Kafka 0.11 or later to support time-based lookups and prevent full stream scans.</div>
        <section class="section context">This task assumes you created a table named kafka_table for a Kafka
            stream.</section>
        <ol class="ol steps"><li class="li step stepexpand">
                <span class="ph cmd">List the table properties and all the partition or offset information for the topic.</span>
                <div class="itemgroup stepxmp"><code class="ph codeph">DESCRIBE EXTENDED kafka_table;</code></div>
            </li><li class="li step stepexpand">
                <span class="ph cmd">Count the number of Kafka records that have timestamps within the past 10
                    minutes.</span>
                <div class="itemgroup stepxmp">
                    <pre class="pre codeblock"><code>SELECT COUNT(*) FROM kafka_table 
  WHERE `__timestamp` &gt;  1000 * to_unix_timestamp(CURRENT_TIMESTAMP - interval '10' MINUTES);  </code></pre>
                </div>
                <div class="itemgroup info">Such a time-based seek requires Kafka 0.11 or later, which has a Kafka broker
                    that supports time-based lookups; otherwise, this query leads to a full stream
                    scan.</div>
            </li><li class="li step stepexpand">
                <span class="ph cmd">Define a view of data consumed within the past 15 minutes and mask specific columns.</span>
                <div class="itemgroup stepxmp"><pre class="pre codeblock"><code>CREATE VIEW last_15_minutes_of_kafka_table AS SELECT  `timestamp`, `user`, delta, 
  ADDED FROM kafka_table 
  WHERE `__timestamp` &gt;  1000 * to_unix_timestamp(CURRENT_TIMESTAMP - interval '15' MINUTES) ; </code></pre></div>
            </li><li class="li step stepexpand">
                <span class="ph cmd">Create a dimension table.</span>
                <div class="itemgroup stepxmp"><pre class="pre codeblock"><code>CREATE TABLE user_table (`user` string, `first_name` string , age int, gender string, comments string) STORED as ORC ;</code></pre></div>
            </li><li class="li step stepexpand">
                <span class="ph cmd">Join the view of the stream over the past 15 minutes to
                        <code class="ph codeph">user_table</code>, group by gender, and compute aggregates over
                    metrics from fact table and dimension tables.</span>
                <div class="itemgroup stepxmp">
                    <pre class="pre codeblock"><code>SELECT SUM(added) AS added, SUM(deleted) AS deleted, AVG(delta) AS delta, AVG(age) AS avg_age , gender 
  FROM last_15_minutes_of_kafka_table  
  JOIN user_table ON `last_15_minutes_of_kafka_table`.`user` = `user_table`.`user`
  GROUP BY gender LIMIT 10;</code></pre>
                </div>
            </li><li class="li step stepexpand">
                <span class="ph cmd">Perform a classical user retention analysis over the Kafka stream consisting of
                    a stream-to-stream join that runs adhoc queries on a view defined over the past
                    15 minutes.</span>
                <div class="itemgroup stepxmp">
                    <pre class="pre codeblock"><code>-- Stream join over the view itself
-- Assuming l15min_wiki is a view of the last 15 minutes
SELECT  COUNT( DISTINCT activity.`user`) AS active_users, 
COUNT(DISTINCT future_activity.`user`) AS retained_users
FROM l15min_wiki AS activity
LEFT JOIN l15min_wiki AS future_activity ON activity.`user` = future_activity.`user`
AND activity.`timestamp` = future_activity.`timestamp` - interval '5' minutes ; 
                    
--  Stream-to-stream join
-- Assuming wiki_kafka_hive is the entire stream.
SELECT floor_hour(activity.`timestamp`), COUNT( DISTINCT activity.`user`) AS active_users, 
COUNT(DISTINCT future_activity.`user`) as retained_users
FROM wiki_kafka_hive AS activity
LEFT JOIN wiki_kafka_hive AS future_activity ON activity.`user` = future_activity.`user`
AND activity.`timestamp` = future_activity.`timestamp` - interval '1' hour 
GROUP BY floor_hour(activity.`timestamp`); </code></pre>
                </div>
            </li></ol>
    </div>
<nav role="navigation" class="related-links"><div class="linklist relinfo"><strong>Related information</strong><br><div><a class="link" href="https://kafka.apache.org/0110/documentation.html" target="_blank">Apache Kafka Documentation</a></div></div></nav></div></article><div class="short-prev"><a href="">«</a></div><div class="short-next"><a href="">»</a></div><div class="up"></div><div class="prev"><a href="">« Getting Started with Apache Nifi</a></div><div class="next">Getting Started: <a href="">Terminology Used in This Guide »</a></div></div><aside class="pubmenu"><div class="product-title"><img class="product-logo" src="/common/img/smaller_icons/icon-hdf.png"><span class="product-name">Cloudera Data Platform</span></div><nav class="ctoc"></nav></aside></main><div class="logo"><a href="/"><img src="//www.cloudera.com/apps/settings/wcm/designs/www/clientlibs/css/assets/icons/favicon/apple-touch-icon-152x152.png"></a></div><nav class="product-drawer"><div class="full-logo"><img src="/common/img/cloudera.png"></div><ul class="products"><li class="cat">Data Platforms</li><li><img src="/common/img/mini_icons/icon-ambari.png"><span class="text">Ambari</span></li><li><img src="/common/img/mini_icons/icon-hdp.png"><span class="text">Data Platform</span></li><li class="active"><img src="/common/img/mini_icons/icon-hdf.png"><span class="text">Dataflow</span></li><li><img src="/common/img/mini_icons/icon-smartsense.png"><span class="text">Smartsense</span></li><li><img src="/common/img/mini_icons/icon-cybersecurity.png"><span class="text">Cybersecurity</span></li><li class="cat">Data Services</li><li><img src="/common/img/mini_icons/icon-dataplane.png"><span class="text">DataPlane Core</span></li><li><img src="/common/img/mini_icons/icon-studio.png"><span class="text">Data Analytics Studio</span></li><li><img src="/common/img/mini_icons/icon-datasteward.png"><span class="text">Data Steward Studio</span></li><li class="cat">Cloud Services</li><li><img src="/common/img/mini_icons/icon-cloudbreak.png"><span class="text">Cloudbreak</span></li><li><img src="/common/img/mini_icons/icon-hdcloud.png"><span class="text">HDCloud for AWS</span></li></ul><div class="open-close">»</div></nav><footer></footer><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script><script src="/common/js/main.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/highlight.min.js" class="test"></script></body></html>