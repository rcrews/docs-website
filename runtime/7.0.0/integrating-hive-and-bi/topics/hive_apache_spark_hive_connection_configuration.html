<!DOCTYPE html><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="UTF-8"><meta name="DC.Type" content="reference"><meta name="description" content="In Spark, you can use the Hive Warehouse Connector for accessing ACID table data in Hive."><meta name="DC.subject" content="Hive, Spark, Hive Warehouse Connector, HiveWarehouseConnector"><meta name="keywords" content="Hive, Spark, Hive Warehouse Connector, HiveWarehouseConnector"><meta name="DC.Relation" scheme="URI" content="../topics/hive_hivewarehouseconnector_for_handling_apache_spark_data.html"><meta name="DC.Relation" scheme="URI" content="https://github.com/hortonworks/hive-warehouse-connector-release"><meta name="DC.Relation" scheme="URI" content="http://docs-stage.cloudera.com/HDPDocuments/CR/CR-1.0.0/developing-spark-applications/content/using_spark_hive_warehouse_connector.html"><meta name="prodname" content="Cloudera Runtime"><meta name="version" content="1"><meta name="release" content="0"><meta name="modification" content="0"><meta name="brand" content="Cloudera Runtime"><meta name="rights" content="© 2019 Cloudera, Inc."><meta name="DC.Date.Created" content="2019-04-15"><meta name="DC.Date.Modified" content="2019-04-15"><meta name="DC.Format" content="XHTML"><meta name="DC.Identifier" content="hive_configure_a_connection_between_apache_spark_and_apache_hive"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="description" content=""><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/5.8.2/css/all.css"><link rel="stylesheet" href="/common/css/main.css"><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/styles/default.min.css"><title>Apache Spark-Apache Hive connection configuration</title></head><body class="hg"><header class="chead"><div class="breadcrumbs">
<span class="bread-home"><a href="/"><i class="fas fa-home"></i><span class="text-home">Cloudera Docs</span></a></span>
<span class="bread-product"></span>
<span class="bread-version"></span>
<span class="bread-category">Category</span></div>
<div class="search"><i class="search-close fas fa-times"></i><input type="text" placeholder="Search Documentation"><i class="fas fa-search"></i></div><div class="launch-search"><i class="fas fa-search"></i></div><div class="launch-pubnav"><i class="fas fa-bars"></i></div></header><main class="cmain"><div class="cpage"><article class="maincontent"><div class="inner-breadcrumbs">Concepts</div><div id="content" aria-labelledby="ariaid-title1">
  <h1 class="title topictitle1" id="ariaid-title1">Apache Spark-Apache Hive connection configuration</h1>
  
  
  <div class="body refbody"><p class="shortdesc">In Spark, you can use the Hive Warehouse Connector for accessing ACID table data in
    Hive. </p>
    <section class="section"><h2 class="title sectiontitle">Prerequisites</h2>
      
      <p class="p">You need to use the following software to connect Spark and Hive using the
        HiveWarehouseConnector library.</p>
      <ul class="ul">
        <li class="li">Spark2</li>
        <li class="li">Hive LLAP<p class="p">The Hive Warehouse Connector (HWC) and low-latency analytical processing
            (LLAP) are required for certain tasks, as shown in the following table:</p><table class="table frame-all" id="hive_configure_a_connection_between_apache_spark_and_apache_hive__table_cdm_cvd_4hb"><caption><span class="table--title-label">Table 1. </span><span class="title">Spark Compatibility</span></caption><colgroup><col style="width:25%"><col style="width:25%"><col style="width:25%"><col style="width:25%"></colgroup><thead class="thead">
                <tr class="row">
                  <th class="entry" id="hive_configure_a_connection_between_apache_spark_and_apache_hive__table_cdm_cvd_4hb__entry__1">Tasks</th>
                  <th class="entry" id="hive_configure_a_connection_between_apache_spark_and_apache_hive__table_cdm_cvd_4hb__entry__2">HWC Required</th>
                  <th class="entry" id="hive_configure_a_connection_between_apache_spark_and_apache_hive__table_cdm_cvd_4hb__entry__3">LLAP Required</th>
                  <th class="entry" id="hive_configure_a_connection_between_apache_spark_and_apache_hive__table_cdm_cvd_4hb__entry__4">Other Requirement/Comments</th>
                </tr>
              </thead><tbody class="tbody">
                <tr class="row">
                  <td class="entry" headers="hive_configure_a_connection_between_apache_spark_and_apache_hive__table_cdm_cvd_4hb__entry__1 ">Read Hive managed tables from Spark</td>
                  <td class="entry" headers="hive_configure_a_connection_between_apache_spark_and_apache_hive__table_cdm_cvd_4hb__entry__2 ">Yes</td>
                  <td class="entry" headers="hive_configure_a_connection_between_apache_spark_and_apache_hive__table_cdm_cvd_4hb__entry__3 ">Yes</td>
                  <td class="entry" headers="hive_configure_a_connection_between_apache_spark_and_apache_hive__table_cdm_cvd_4hb__entry__4 ">Ranger ACLs enforced.</td>
                </tr>
                <tr class="row">
                  <td class="entry" headers="hive_configure_a_connection_between_apache_spark_and_apache_hive__table_cdm_cvd_4hb__entry__1 ">Write Hive managed tables from Spark</td>
                  <td class="entry" headers="hive_configure_a_connection_between_apache_spark_and_apache_hive__table_cdm_cvd_4hb__entry__2 ">Yes</td>
                  <td class="entry" headers="hive_configure_a_connection_between_apache_spark_and_apache_hive__table_cdm_cvd_4hb__entry__3 ">No</td>
                  <td class="entry" headers="hive_configure_a_connection_between_apache_spark_and_apache_hive__table_cdm_cvd_4hb__entry__4 ">Ranger ACLs enforced.</td>
                </tr>
                <tr class="row">
                  <td class="entry" headers="hive_configure_a_connection_between_apache_spark_and_apache_hive__table_cdm_cvd_4hb__entry__1 ">Read Hive external tables from Spark</td>
                  <td class="entry" headers="hive_configure_a_connection_between_apache_spark_and_apache_hive__table_cdm_cvd_4hb__entry__2 ">No</td>
                  <td class="entry" headers="hive_configure_a_connection_between_apache_spark_and_apache_hive__table_cdm_cvd_4hb__entry__3 ">Only if HWC is used</td>
                  <td class="entry" headers="hive_configure_a_connection_between_apache_spark_and_apache_hive__table_cdm_cvd_4hb__entry__4 ">Table must be defined in Spark catalog. Ranger ACLs not enforced.</td>
                </tr>
                <tr class="row">
                  <td class="entry" headers="hive_configure_a_connection_between_apache_spark_and_apache_hive__table_cdm_cvd_4hb__entry__1 ">Write Hive external tables from Spark</td>
                  <td class="entry" headers="hive_configure_a_connection_between_apache_spark_and_apache_hive__table_cdm_cvd_4hb__entry__2 ">No</td>
                  <td class="entry" headers="hive_configure_a_connection_between_apache_spark_and_apache_hive__table_cdm_cvd_4hb__entry__3 ">No</td>
                  <td class="entry" headers="hive_configure_a_connection_between_apache_spark_and_apache_hive__table_cdm_cvd_4hb__entry__4 ">Ranger ACLs enforced.</td>
                </tr>
                <tr class="row">
                  <td class="entry" headers="hive_configure_a_connection_between_apache_spark_and_apache_hive__table_cdm_cvd_4hb__entry__1 ">Read Spark tables</td>
                  <td class="entry" headers="hive_configure_a_connection_between_apache_spark_and_apache_hive__table_cdm_cvd_4hb__entry__2 ">Yes</td>
                  <td class="entry" headers="hive_configure_a_connection_between_apache_spark_and_apache_hive__table_cdm_cvd_4hb__entry__3 ">Yes</td>
                  <td class="entry" headers="hive_configure_a_connection_between_apache_spark_and_apache_hive__table_cdm_cvd_4hb__entry__4 ">Ranger ACLs enforced.</td>
                </tr>
                <tr class="row">
                  <td class="entry" headers="hive_configure_a_connection_between_apache_spark_and_apache_hive__table_cdm_cvd_4hb__entry__1 ">Write Spark tables</td>
                  <td class="entry" headers="hive_configure_a_connection_between_apache_spark_and_apache_hive__table_cdm_cvd_4hb__entry__2 ">Yes</td>
                  <td class="entry" headers="hive_configure_a_connection_between_apache_spark_and_apache_hive__table_cdm_cvd_4hb__entry__3 ">No</td>
                  <td class="entry" headers="hive_configure_a_connection_between_apache_spark_and_apache_hive__table_cdm_cvd_4hb__entry__4 ">Ranger ACLs enforced.</td>
                </tr>
              </tbody></table><p class="p">You need low-latency analytical processing (LLAP) to read ACID, or other
            Hive-managed tables, from Spark. You do not need LLAP to write to ACID, or other managed
            tables, from Spark. The HWC library internally uses the Hive Streaming API and LOAD DATA
            Hive commands to write the data. You do not need LLAP to access external tables from
            Spark with caveats shown in the table above.</p></li>
      </ul>
    </section>
    <section class="section"><h2 class="title sectiontitle">Required properties</h2>
      
      <p class="p">You must add several Spark properties through <code class="ph codeph">spark-2-defaults</code> in Cloudera
        Manager to use the Hive Warehouse Connector for accessing data in Hive. Alternatively,
        configuration can be provided for each job using <code class="ph codeph">hive -\-conf</code>.</p><ul class="ul" id="hive_configure_a_connection_between_apache_spark_and_apache_hive__ul_eqd_zy5_33b">
          <li class="li"><code class="ph codeph">spark.sql.hive.hiveserver2.jdbc.url</code> <p class="p">The URL for HiveServer2 Interactive</p></li>
          <li class="li"><code class="ph codeph">spark.datasource.hive.warehouse.metastoreUri</code><p class="p">The URI for the metastore.</p></li>
          <li class="li"><code class="ph codeph">spark.datasource.hive.warehouse.load.staging.dir</code><p class="p">The HDFS temp directory for batch writes to Hive, /tmp for example</p></li>
          <li class="li"><code class="ph codeph">spark.hadoop.hive.llap.daemon.service.hosts</code><p class="p">The application name for LLAP service</p></li>
          <li class="li"><code class="ph codeph">spark.hadoop.hive.zookeeper.quorum</code><p class="p">ZooKeeper hosts used by LLAP</p></li>
        </ul>
        <p class="p">Set the values of these properties as
        follows:</p>
          <ul class="ul">
           <li class="li"><code class="ph codeph">spark.datasource.hive.warehouse.metastoreUri</code>: Copy the value from
          hive.metastore.uris. In Hive, at the hive&gt; prompt, enter <code class="ph codeph">set
            hive.metastore.uris</code> and copy the output. For example,
            <code class="ph codeph">thrift://mycluster-1.com:9083</code>.</li>

              <li class="li"><code class="ph codeph">spark.hadoop.hive.llap.daemon.service.hosts</code>: Copy the value from
          TBD &gt; <code class="ph codeph">hive.llap.daemon.service.hosts</code>.</li>
              <li class="li"><code class="ph codeph">spark.hadoop.hive.zookeeper.quorum</code>: Copy the value from
            TBD<code class="ph codeph">hive.zookeeper.quorum</code></li>
           </ul>
    </section>
    <section class="section"><h2 class="title sectiontitle">Other HWC properties</h2>
      
      <p class="p">The <code class="ph codeph">spark.datasource.hive.warehouse.write.path.strictColumnNamesMapping</code> validates
        the mapping of columns against those in Hive to alert the user to input errors.
        Default = true.</p>
    </section>
    
    <section class="section"><h2 class="title sectiontitle">Spark on a Kerberized YARN cluster</h2>
      
      <p class="p">In Spark client mode on a kerberized Yarn cluster, set the following property:
          <code class="ph codeph">spark.sql.hive.hiveserver2.jdbc.url.principal</code>.  This property must be
        equal to <code class="ph codeph">hive.server2.authentication.kerberos.principal</code>. In Cloudera Manager, TBD.
        <code class="ph codeph">hive.server2.authentication.kerberos.principal</code>. </p>
<div class="p">In Spark cluster mode on a kerberized YARN cluster, set the following property:
     <ul class="ul">
       
    <li class="li">Property: <code class="ph codeph">spark.security.credentials.hiveserver2.enabled</code></li>
          <li class="li">Description: Must use Spark ServiceCredentialProvider and set equal to a boolean, such as
              <code class="ph codeph">true</code></li>
        <li class="li">Comment: <code class="ph codeph">true</code> by default</li>
      </ul>
</div>
    </section>
  </div>
<nav role="navigation" class="related-links"><div class="familylinks"><div class="parentlink"><strong>Parent topic:</strong> <a class="link" href="../topics/hive_hivewarehouseconnector_for_handling_apache_spark_data.html" title="The Hive Warehouse Connector (HWC) is a Spark library/plugin that is launched with the Spark app. You need to understand how to use HWC to access Spark tables from Hive. You also export tables to Hive from Spark and vice versa using this connector.">Hive Warehouse Connector for accessing Apache Spark data</a></div></div><div class="linklist relinfo"><strong>Related information</strong><br><div><a class="link" href="https://github.com/hortonworks/hive-warehouse-connector-release" target="_blank">HiveWarehouseConnector Github project (select a feature branch)</a></div><div><a class="link" href="http://docs-stage.cloudera.com/HDPDocuments/CR/CR-1.0.0/developing-spark-applications/content/using_spark_hive_warehouse_connector.html" target="_blank">HiveWarehouseConnector for handling Apache Spark data</a></div></div></nav></div></article><div class="short-prev"><a href="">«</a></div><div class="short-next"><a href="">»</a></div><div class="up"></div><div class="prev"><a href="">« Getting Started with Apache Nifi</a></div><div class="next">Getting Started: <a href="">Terminology Used in This Guide »</a></div></div><aside class="pubmenu"><div class="product-title"><img class="product-logo" src="/common/img/smaller_icons/icon-hdf.png"><span class="product-name">Cloudera Data Platform</span></div><nav class="ctoc"></nav></aside></main><div class="logo"><a href="/"><img src="//www.cloudera.com/apps/settings/wcm/designs/www/clientlibs/css/assets/icons/favicon/apple-touch-icon-152x152.png"></a></div><nav class="product-drawer"><div class="full-logo"><img src="/common/img/cloudera.png"></div><ul class="products"><li class="cat">Data Platforms</li><li><img src="/common/img/mini_icons/icon-ambari.png"><span class="text">Ambari</span></li><li><img src="/common/img/mini_icons/icon-hdp.png"><span class="text">Data Platform</span></li><li class="active"><img src="/common/img/mini_icons/icon-hdf.png"><span class="text">Dataflow</span></li><li><img src="/common/img/mini_icons/icon-smartsense.png"><span class="text">Smartsense</span></li><li><img src="/common/img/mini_icons/icon-cybersecurity.png"><span class="text">Cybersecurity</span></li><li class="cat">Data Services</li><li><img src="/common/img/mini_icons/icon-dataplane.png"><span class="text">DataPlane Core</span></li><li><img src="/common/img/mini_icons/icon-studio.png"><span class="text">Data Analytics Studio</span></li><li><img src="/common/img/mini_icons/icon-datasteward.png"><span class="text">Data Steward Studio</span></li><li class="cat">Cloud Services</li><li><img src="/common/img/mini_icons/icon-cloudbreak.png"><span class="text">Cloudbreak</span></li><li><img src="/common/img/mini_icons/icon-hdcloud.png"><span class="text">HDCloud for AWS</span></li></ul><div class="open-close">»</div></nav><footer></footer><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script><script src="/common/js/main.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/highlight.min.js" class="test"></script></body></html>