---
layout: foyer
breadcrumb-title: Cloudera Runtime How To
title: Storage

# How-to publications related to
# * HDFS
# * Kudu

publications:
  - title: Scaling Namespaces and Optimizing Data Storage
    url: scaling-namespaces/index.html
    description: >-
      Provides information about scaling namespaces, optimizing data
      storage, and optimizing performance of Apache HDFS.

  - title: Configuring Data Protection
    url: data-protection/index.html
    description: >-
      Provides information about configuring data protection on a Hadoop
      cluster.

  - title: Configuring HDFS ACLs
    url: hdfs-acls/index.html
    description: >-
      Describes the procedure to configure Access Control Lists (ACLs)
      on Apache HDFS.

  - title: Configuring HDFS Encryption
    url: hdfs-encryption/index.html
    description: >-
      Describes the procedure to configure HDFS Data at Rest encryption.

  - title: Administering Apache Kudu
    url: administering-kudu/index.html
    description: >-
      Describes common administrative tasks and Apache Kudu workflows.

  - title: Developing Applications with Apache Kudu
    url: kudu-development/index.html
    description: >-
      Provides reference examples to use C++ and Java client APIs to
      develop apps using Apache Kudu.

  - title: Using Apache Impala with Apache Kudu
    url: kudu-integration/index.html
    description: >-
      Gravida primis lobortis posuere augue adipiscing id leo consequat
      metus, nam in consectetur auctor libero fermentum dui inceptos
      euismod, faucibus commodo vehicula accumsan penatibus risus
      sodales ultricies, nisl orci sem habitant et nunc rhoncus montes
---
Cloudera Runtime provides different types of storage components that you
can use depending on your data requirements. Apache HBase is a NoSQL
database that provides real-time read/write access to those large
datasets. Apache Kudu is a columnar data store that enables fast
analytics on rapidly changing data. Apache HDFS is a distributed file
system for storing large volumes of data.
